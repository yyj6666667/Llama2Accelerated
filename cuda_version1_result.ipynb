{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLdoj4cz-xal"
      },
      "source": [
        "# Run.c\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/karpathy/llama2.c/blob/master/run.ipynb)\n",
        "\n",
        "More details can be found in the [README.md](README.md) ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Une3Ozlnu1B7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'tem-force'...\n",
            "remote: Enumerating objects: 107, done.\u001b[K\n",
            "remote: Counting objects: 100% (107/107), done.\u001b[K\n",
            "remote: Compressing objects: 100% (79/79), done.\u001b[K\n",
            "remote: Total 107 (delta 36), reused 91 (delta 20), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (107/107), 1.08 MiB | 29.13 MiB/s, done.\n",
            "Resolving deltas: 100% (36/36), done.\n",
            "sample_data  tem-force\n",
            "/content/tem-force\n"
          ]
        }
      ],
      "source": [
        "#@title Clone Project\n",
        "!rm -rf tem-force\n",
        "!git clone https://github.com/yyj6666667/tem-force\n",
        "!ls\n",
        "%cd tem-force"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "thm0ZBrtSgoC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "download_url: https://huggingface.co/karpathy/tinyllamas/resolve/main/stories42M.bin\n",
            "--2026-01-10 14:27:38--  https://huggingface.co/karpathy/tinyllamas/resolve/main/stories42M.bin\n",
            "Resolving huggingface.co (huggingface.co)... 13.35.202.34, 13.35.202.97, 13.35.202.121, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.35.202.34|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://us.gcp.cdn.hf.co/xet-bridge-us/64c19eb0275dc8cd7f170b8f/20ab6952f8b77338484a45f788d50ed30dfda285f9954758b75d7deefd120d26?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27stories42M.bin%3B+filename%3D%22stories42M.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1768058858&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiRXBvY2hUaW1lIjoxNzY4MDU4ODU4fX0sIlJlc291cmNlIjoiaHR0cHM6Ly91cy5nY3AuY2RuLmhmLmNvL3hldC1icmlkZ2UtdXMvNjRjMTllYjAyNzVkYzhjZDdmMTcwYjhmLzIwYWI2OTUyZjhiNzczMzg0ODRhNDVmNzg4ZDUwZWQzMGRmZGEyODVmOTk1NDc1OGI3NWQ3ZGVlZmQxMjBkMjZcXD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=PZIUZcgDfHq7QQw-TBrc1mno8JCAdj%7ECAvjHSfrBGGsKNU4tMGWDOS4338wflj0vJ3H77O8Rsh-udoVv1dg7cfbRgHHDsET6OvSR9KPpIlMH9gjSfurxMj-j1mr40muhNGNAsSQjd00ckDeVbRu-MAIxaXmZQnHLHY4hNdu9xp%7Er6Q3zGl6of3mBObs2ETsSWUmEnGGeqRds7PHwVxyipmkKFXGBWLmLTuiSEBIqQy4Fuly6Y5ZHvCzVW2qnqDhAh%7ER0Z4xJVzwPMa3aJpLeTrCVxNzAlGAo3kQSoh-02Ao0XFE6w0ZrA-pR171UJvPGrxeiwC9UOc-3cUfoejvfoA__&Key-Pair-Id=KJLH8B0YWU4Y8M [following]\n",
            "--2026-01-10 14:27:38--  https://us.gcp.cdn.hf.co/xet-bridge-us/64c19eb0275dc8cd7f170b8f/20ab6952f8b77338484a45f788d50ed30dfda285f9954758b75d7deefd120d26?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27stories42M.bin%3B+filename%3D%22stories42M.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1768058858&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiRXBvY2hUaW1lIjoxNzY4MDU4ODU4fX0sIlJlc291cmNlIjoiaHR0cHM6Ly91cy5nY3AuY2RuLmhmLmNvL3hldC1icmlkZ2UtdXMvNjRjMTllYjAyNzVkYzhjZDdmMTcwYjhmLzIwYWI2OTUyZjhiNzczMzg0ODRhNDVmNzg4ZDUwZWQzMGRmZGEyODVmOTk1NDc1OGI3NWQ3ZGVlZmQxMjBkMjZcXD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=PZIUZcgDfHq7QQw-TBrc1mno8JCAdj%7ECAvjHSfrBGGsKNU4tMGWDOS4338wflj0vJ3H77O8Rsh-udoVv1dg7cfbRgHHDsET6OvSR9KPpIlMH9gjSfurxMj-j1mr40muhNGNAsSQjd00ckDeVbRu-MAIxaXmZQnHLHY4hNdu9xp%7Er6Q3zGl6of3mBObs2ETsSWUmEnGGeqRds7PHwVxyipmkKFXGBWLmLTuiSEBIqQy4Fuly6Y5ZHvCzVW2qnqDhAh%7ER0Z4xJVzwPMa3aJpLeTrCVxNzAlGAo3kQSoh-02Ao0XFE6w0ZrA-pR171UJvPGrxeiwC9UOc-3cUfoejvfoA__&Key-Pair-Id=KJLH8B0YWU4Y8M\n",
            "Resolving us.gcp.cdn.hf.co (us.gcp.cdn.hf.co)... 34.120.165.110\n",
            "Connecting to us.gcp.cdn.hf.co (us.gcp.cdn.hf.co)|34.120.165.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 167020572 (159M) [application/octet-stream]\n",
            "Saving to: ‘stories42M.bin’\n",
            "\n",
            "stories42M.bin      100%[===================>] 159.28M  12.0MB/s    in 9.4s    \n",
            "\n",
            "2026-01-10 14:27:48 (17.0 MB/s) - ‘stories42M.bin’ saved [167020572/167020572]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#@title Pick Your Model\n",
        "\n",
        "#@markdown Choose model\n",
        "model = \"stories42M\" #@param [\"stories15M\", \"stories42M\", \"stories110M\"]\n",
        "\n",
        "download_url = \"\"\n",
        "\n",
        "if(model == \"stories15M\"):\n",
        "  download_url = \"https://huggingface.co/karpathy/tinyllamas/resolve/main/stories15M.bin\"\n",
        "if(model == \"stories42M\"):\n",
        "  download_url = \"https://huggingface.co/karpathy/tinyllamas/resolve/main/stories42M.bin\"\n",
        "if(model == \"stories110M\"):\n",
        "  download_url = \"https://huggingface.co/karpathy/tinyllamas/resolve/main/stories110M.bin\"\n",
        "\n",
        "print(f\"download_url: {download_url}\")\n",
        "\n",
        "!wget $download_url\n",
        "\n",
        "model_file = model + \".bin\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gcc -Ofast -o run run.c -lm\n",
            "gcc -Ofast -o runq runq.c -lm\n"
          ]
        }
      ],
      "source": [
        "#CPU;\n",
        "!make runfast"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "若使用 CUDA 优化，需执行nvcc -arch=compute_35 -O3 -std=c++17 -o run run.c -lm命令编译代码；若使用了 cuBLAS 库，则执行nvcc -arch=compute_35 -O3 -std=c++17 -o run run.c -lm -L/usr/local/lib64 -lcublas编译代码；若采用 AVX、OpenMP 等其他优化方法，则直接执行make run即可。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[01m\u001b[0m\u001b[01mrun_version1.cu(586)\u001b[0m: \u001b[01;35mwarning\u001b[0m #2464-D: conversion from a string literal to \"char *\" is deprecated\n",
            "          int dummy_prefix = str_lookup(\" \", t->sorted_vocab, t->vocab_size);\n",
            "                                        ^\n",
            "\n",
            "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01mrun_version1.cu(833)\u001b[0m: \u001b[01;35mwarning\u001b[0m #2464-D: conversion from a string literal to \"char *\" is deprecated\n",
            "      char *empty_prompt = \"\";\n",
            "                           ^\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01mrun_version1.cu(1013)\u001b[0m: \u001b[01;35mwarning\u001b[0m #2464-D: conversion from a string literal to \"char *\" is deprecated\n",
            "      char *tokenizer_path = \"tokenizer.bin\";\n",
            "                             ^\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01mrun_version1.cu(1019)\u001b[0m: \u001b[01;35mwarning\u001b[0m #2464-D: conversion from a string literal to \"char *\" is deprecated\n",
            "      char *mode = \"generate\";\n",
            "                   ^\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01mrun_version1.cu(586)\u001b[0m: \u001b[01;35mwarning\u001b[0m #2464-D: conversion from a string literal to \"char *\" is deprecated\n",
            "          int dummy_prefix = str_lookup(\" \", t->sorted_vocab, t->vocab_size);\n",
            "                                        ^\n",
            "\n",
            "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01mrun_version1.cu(833)\u001b[0m: \u001b[01;35mwarning\u001b[0m #2464-D: conversion from a string literal to \"char *\" is deprecated\n",
            "      char *empty_prompt = \"\";\n",
            "                           ^\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01mrun_version1.cu(921)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"prev_token\"\u001b[0m was declared but never referenced\n",
            "      int prev_token;\n",
            "          ^\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01mrun_version1.cu(1013)\u001b[0m: \u001b[01;35mwarning\u001b[0m #2464-D: conversion from a string literal to \"char *\" is deprecated\n",
            "      char *tokenizer_path = \"tokenizer.bin\";\n",
            "                             ^\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01mrun_version1.cu(1019)\u001b[0m: \u001b[01;35mwarning\u001b[0m #2464-D: conversion from a string literal to \"char *\" is deprecated\n",
            "      char *mode = \"generate\";\n",
            "                   ^\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#GPU\n",
        "#!nvcc -O3 -o run run.cu -lcudart -lm\n",
        "\n",
        "!nvcc -O3 -std=c++14 -arch=sm_75 -o run run_version1.cu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nvprof: NVIDIA (R) Cuda command line profiler\n",
            "Copyright (c) 2012 - 2024 NVIDIA Corporation\n",
            "Release version 12.5.82 (21)\n",
            "NVIDIA Nsight Systems version 2023.2.3.1004-33186433v0\n"
          ]
        }
      ],
      "source": [
        "#tool prepare\n",
        "!git clone https://github.com/brendangregg/FlameGraph 2>/dev/null || echo \n",
        "\"FlameGraph Already cloned\"\n",
        "!apt-get install -y cuda-nsight-systems-12-2 >/dev/null || echo \"nsys is installed\"\n",
        "\n",
        "!nvprof --version\n",
        "!nsys --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "One day, a little boy named Tim found a scooter in his yard. He was so happy. Tim wanted to ride the scooter all day. He did not want to share it with his friends. Tim was being selfish.\n",
            "Tim rode the scooter down the hill. He went very fast. But then, something unexpected happened. The scooter began to move on its own! Tim was so surprised. He stopped and tried to ride again. But the scooter was still moving.\n",
            "Tim called his friends to help. They all pushed the scooter together. The scooter started to go faster. Tim was happy. He learned that sharing can be fun. From that day on, Tim was not selfish anymore.\n",
            "==6544== NVPROF is profiling process 6544, command: ./run stories42M.bin\n",
            "achieved tok/s: 21.552915\n",
            "==6544== Profiling application: ./run stories42M.bin\n",
            "==6544== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   91.56%  4.35212s     17898  243.16us     799ns  17.876ms  [CUDA memcpy HtoD]\n",
            "                    8.03%  381.90ms      8949  42.674us  18.591us  941.48us  matmulkernel(float*, float*, float*, int, int)\n",
            "                    0.41%  19.325ms      8949  2.1590us  1.6950us  15.200us  [CUDA memcpy DtoH]\n"
          ]
        }
      ],
      "source": [
        "#备选方案nvprof\n",
        "\n",
        "# 2. 运行 nvprof\n",
        "!nvprof --print-gpu-summary ./run stories42M.bin  2> nvprof_output.txt\n",
        "# 步骤 1: 提取 GPU activities 部分\n",
        "!cat nvprof_output.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "OgAc3KjuT-NM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: stories42M.bin, max_token: 256, temperature: 0.8, top_p: 0.9, prompt: One day, Lily met a Shoggoth\n",
            "----------------------------\n",
            "\n",
            "One day, Lily met a Shoggoth. He was very shiny and sweet. He said to Lily, \"I have a special gift for you. It's a horn.\" Lily was so excited. She couldn't believe it. She asked the Shogggoth, \"What does it do?\" The Shoggoth replied, \"You have to blow it and make a loud noise.\" Lily was delighted. She blew the horn and it made a loud noise. She smiled and said, \"Wow, it's so loud!\" The Shogggoth smiled and said, \"You're very welcome. Have a nice day!\" Lily thanked the Shogggest and she ran off, skipping happily.\n",
            "achieved tok/s: 322.134387\n"
          ]
        }
      ],
      "source": [
        "#@title Generate Stories\n",
        "\n",
        "# Generate args\n",
        "max_token = 256 #@param {type:\"slider\", min:32, max:1024, step:32}\n",
        "temperature = 0.8 #@param {type:\"slider\", min:0.0, max:1, step:0.05}\n",
        "top_p = 0.9 #@param {type:\"slider\", min:0.0, max:1.0, step:0.05}\n",
        "prompt = \"One day, Lily met a Shoggoth\" #@param {type:\"string\"}\n",
        "\n",
        "print(f\"model: {model_file}, max_token: {max_token}, temperature: {temperature}, top_p: {top_p}, prompt: {prompt}\")\n",
        "print(f\"----------------------------\\n\")\n",
        "\n",
        "cmd = f'./run {model_file} -t {temperature} -p {top_p} -n {max_token} -i \"{prompt}\"'\n",
        "!{cmd}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Once upon a time, there was a little girl named Lily. One day, Lily's mommy asked her to help mop the floor. Lily was excited to help her mommy, so she grabbed the mop and started to clean. \n",
            "As she was cleaning, she noticed that the floor was very slippery. She was careful not to fall as she mops. Suddenly, she heard her mommy's phone ring. Her mommy answered the phone and talked for a while. \n",
            "Lily continued to mop the floor, but she started to feel dizzy. She stopped cleaning and sat down on the couch. Her mommy noticed that she was feeling dizzy and asked her if she wanted to take a break. Lily nodded her head and her mommy gave her some water to drink. After a few sips, Lily felt much better. She finished mopping the floor and her mommy thanked her for being such a good helper.\n",
            "achieved tok/s: 21.048490\n",
            "Generating '/tmp/nsys-report-5837.qdstrm'\n",
            "[1/8] [========================100%] yyj_report.nsys-rep\n",
            "[2/8] [========================100%] yyj_report.sqlite\n",
            "[3/8] Executing 'nvtx_sum' stats report\n",
            "SKIPPED: /content/tem-force/yyj_report.sqlite does not contain NV Tools Extension (NVTX) data.\n",
            "[4/8] Executing 'osrt_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Num Calls    Avg (ns)      Med (ns)     Min (ns)   Max (ns)    StdDev (ns)            Name         \n",
            " --------  ---------------  ---------  ------------  -------------  --------  -----------  ------------  ----------------------\n",
            "     99.3   10,639,242,803        115  92,515,154.8  100,160,854.0    63,102  311,294,694  34,942,124.6  poll                  \n",
            "      0.6       67,020,093        536     125,037.5       12,563.5       429   18,842,138     980,284.3  ioctl                 \n",
            "      0.0        4,230,586        214      19,769.1       10,312.5       705       89,288      19,170.4  fflush                \n",
            "      0.0        3,316,800          8     414,600.0        5,602.0     2,785    3,269,727   1,153,653.0  munmap                \n",
            "      0.0        1,966,088         31      63,422.2       10,460.0     8,034    1,222,309     216,519.8  mmap64                \n",
            "      0.0          522,634         10      52,263.4       50,810.5    24,636      112,754      25,852.5  sem_timedwait         \n",
            "      0.0          515,158          1     515,158.0      515,158.0   515,158      515,158           0.0  pthread_cond_wait     \n",
            "      0.0          451,688         17      26,569.9        6,787.0     1,911      233,723      55,670.3  mmap                  \n",
            "      0.0          396,750         49       8,096.9        7,902.0     2,181       18,382       2,894.9  open64                \n",
            "      0.0          239,102         42       5,692.9        3,310.5     1,475       32,050       6,069.9  fopen                 \n",
            "      0.0          102,083          2      51,041.5       51,041.5    50,687       51,396         501.3  pthread_create        \n",
            "      0.0           61,684         12       5,140.3        5,671.5     2,770        7,530       1,550.3  write                 \n",
            "      0.0           54,236         35       1,549.6        1,177.0       726        5,020       1,129.7  fclose                \n",
            "      0.0           37,271          6       6,211.8        5,935.0     1,474       13,315       4,283.1  open                  \n",
            "      0.0           36,154         20       1,807.7           46.0        45       35,217       7,863.7  fgets                 \n",
            "      0.0           31,739         64         495.9          509.5       188          968         191.9  fcntl                 \n",
            "      0.0           22,478         15       1,498.5        1,318.0       804        3,520         730.0  read                  \n",
            "      0.0           14,884          3       4,961.3        3,775.0     2,871        8,238       2,873.4  pipe2                 \n",
            "      0.0           13,943          2       6,971.5        6,971.5     5,055        8,888       2,710.3  socket                \n",
            "      0.0            9,351          1       9,351.0        9,351.0     9,351        9,351           0.0  connect               \n",
            "      0.0            7,279          2       3,639.5        3,639.5     2,054        5,225       2,242.2  pthread_cond_broadcast\n",
            "      0.0            5,208          2       2,604.0        2,604.0     2,420        2,788         260.2  fwrite                \n",
            "      0.0            3,000          8         375.0          367.0       258          585         107.7  dup                   \n",
            "      0.0            1,749          1       1,749.0        1,749.0     1,749        1,749           0.0  bind                  \n",
            "      0.0              825          1         825.0          825.0       825          825           0.0  listen                \n",
            "\n",
            "[5/8] Executing 'cuda_api_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Num Calls    Avg (ns)    Med (ns)   Min (ns)   Max (ns)    StdDev (ns)            Name         \n",
            " --------  ---------------  ---------  ------------  ---------  --------  -----------  ------------  ----------------------\n",
            "     81.4    8,099,738,677     24,510     330,466.7  210,333.5     3,032   18,506,842   1,357,612.0  cudaMemcpyAsync       \n",
            "     15.8    1,569,556,533     12,255     128,074.8  111,647.0    23,439    1,843,597     123,187.9  cudaMemcpy            \n",
            "      1.5      149,024,170     12,255      12,160.3   10,585.0     5,997    1,131,122      14,309.3  cudaLaunchKernel      \n",
            "      1.3      128,175,133          3  42,725,044.3  153,489.0     8,201  128,013,443  73,861,955.6  cudaMalloc            \n",
            "      0.0        1,887,988          3     629,329.3  782,722.0    24,807    1,080,459     544,286.0  cudaFree              \n",
            "      0.0            2,136          1       2,136.0    2,136.0     2,136        2,136           0.0  cuModuleGetLoadingMode\n",
            "\n",
            "[6/8] Executing 'cuda_gpu_kern_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Instances  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)                        Name                       \n",
            " --------  ---------------  ---------  --------  --------  --------  --------  -----------  -------------------------------------------------\n",
            "    100.0      523,064,898     12,255  42,681.8  19,072.0    18,623   941,388    120,460.9  matmulkernel(float *, float *, float *, int, int)\n",
            "\n",
            "[7/8] Executing 'cuda_gpu_mem_time_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Count   Avg (ns)   Med (ns)  Min (ns)   Max (ns)   StdDev (ns)      Operation     \n",
            " --------  ---------------  ------  ---------  --------  --------  ----------  -----------  ------------------\n",
            "     99.6    6,044,790,954  24,510  246,625.5  44,175.0       768  18,290,767  1,336,543.2  [CUDA memcpy HtoD]\n",
            "      0.4       26,379,243  12,255    2,152.5   1,984.0     1,695      13,280      1,322.4  [CUDA memcpy DtoH]\n",
            "\n",
            "[8/8] Executing 'cuda_gpu_mem_size_sum' stats report\n",
            "\n",
            " Total (MB)  Count   Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)      Operation     \n",
            " ----------  ------  --------  --------  --------  --------  -----------  ------------------\n",
            " 35,876.613  24,510     1.464     0.527     0.002    65.536        6.125  [CUDA memcpy HtoD]\n",
            "     64.067  12,255     0.005     0.002     0.002     0.128        0.016  [CUDA memcpy DtoH]\n",
            "\n",
            "Generated:\n",
            "    /content/tem-force/yyj_report.nsys-rep\n",
            "    /content/tem-force/yyj_report.sqlite\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "# 详细采集（包含 CUDA、cuBLAS、cuDNN、NVTX、OS 运行时）\n",
        "!nsys profile -t cuda,cublas,cudnn,nvtx,osrt --stats=true -o yyj_report ./run stories42M.bin\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
